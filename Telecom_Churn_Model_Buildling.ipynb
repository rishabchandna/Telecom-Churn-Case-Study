{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Sanity checks on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('telecom_churn_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let get the shape of the data frame before we start\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let get the shape of the data frame before we start\n",
    "# currently commenting this out as it is taking a long time for the 1 lakh records.\n",
    "# df.describe  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data cleaning and Preparation\n",
    "\n",
    "## Let us start with Data cleaning and prepare data for analysis\n",
    "\n",
    "### Start with the treatment of Null Values - more than 74% drop the column, less than 3%, replace null with 0, Rest impute with mean/median/mode according to the type of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#finding the null percentage value in the columns\n",
    "columns = df.columns\n",
    "percent_missing_Nulls = (df.isnull().sum() * 100) / df.shape[0]\n",
    "\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,\n",
    "                                 'percent_missing': percent_missing_Nulls})\n",
    "\n",
    "#dropping the columns whose missing values is more than 70%\n",
    "threshold_percentage = 74\n",
    "\n",
    "filtered_cols = list(missing_value_df[missing_value_df.percent_missing > threshold_percentage].column_name)\n",
    "\n",
    "df = df.drop(filtered_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #finding the null percentage value in the columns\n",
    "columns = df.columns\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "#dropping the columns whose missing values is more than 70%\n",
    "percentage = 3\n",
    "filtered_cols = list(missing_value_df[(missing_value_df.percent_missing<percentage) & (missing_value_df.percent_missing>0) ].column_name)\n",
    "\n",
    "filtered_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Inference : the first 3 are number value, rest are date values and we will have different treatment for dates </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imputing the null value\n",
    "num_cols = df.select_dtypes('number').columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing the null values with 0\n",
    "df['loc_og_t2o_mou'].fillna(0.0,inplace=True)\n",
    "df['std_og_t2o_mou'].fillna(0.0,inplace=True)\n",
    "df['loc_ic_t2o_mou'].fillna(0.0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes('float').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the last data of each month where null values are present.\n",
    "df['last_date_of_month_7'].fillna('7/31/2014',inplace=True)\n",
    "df['last_date_of_month_8'].fillna('8/31/2014',inplace=True)\n",
    "df['last_date_of_month_9'].fillna('9/30/2014',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df(df, col):\n",
    "    if df[col].dtype == \"float\":\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median value\n",
    "\n",
    "impute_df(df,'onnet_mou_6')\n",
    "impute_df(df,'onnet_mou_7')\n",
    "impute_df(df,'onnet_mou_8')\n",
    "impute_df(df,'onnet_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "\n",
    "impute_df(df,'offnet_mou_6')\n",
    "impute_df(df,'offnet_mou_7')\n",
    "impute_df(df,'offnet_mou_8')\n",
    "impute_df(df,'offnet_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'roam_ic_mou_6')\n",
    "impute_df(df,'roam_ic_mou_7')\n",
    "impute_df(df,'roam_ic_mou_8')\n",
    "impute_df(df,'roam_ic_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "\n",
    "impute_df(df,'roam_og_mou_6')\n",
    "impute_df(df,'roam_og_mou_7')\n",
    "impute_df(df,'roam_og_mou_8')\n",
    "impute_df(df,'roam_og_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_og_t2t_mou_6')\n",
    "impute_df(df,'loc_og_t2t_mou_7')\n",
    "impute_df(df,'loc_og_t2t_mou_8')\n",
    "impute_df(df,'loc_og_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_og_t2t_mou_6')\n",
    "impute_df(df,'loc_og_t2t_mou_7')\n",
    "impute_df(df,'loc_og_t2t_mou_8')\n",
    "impute_df(df,'loc_og_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_og_t2t_mou_6')\n",
    "impute_df(df,'loc_og_t2t_mou_7')\n",
    "impute_df(df,'loc_og_t2t_mou_8')\n",
    "impute_df(df,'loc_og_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_og_t2m_mou_6')\n",
    "impute_df(df,'loc_og_t2m_mou_7')\n",
    "impute_df(df,'loc_og_t2m_mou_8')\n",
    "impute_df(df,'loc_og_t2m_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_og_t2f_mou_6')\n",
    "impute_df(df,'loc_og_t2f_mou_7')\n",
    "impute_df(df,'loc_og_t2f_mou_8')\n",
    "impute_df(df,'loc_og_t2f_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median value\n",
    "impute_df(df,'loc_og_t2f_mou_6')\n",
    "impute_df(df,'loc_og_t2f_mou_7')\n",
    "impute_df(df,'loc_og_t2f_mou_8')\n",
    "impute_df(df,'loc_og_t2f_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_og_t2c_mou_6')\n",
    "impute_df(df,'loc_og_t2c_mou_7')\n",
    "impute_df(df,'loc_og_t2c_mou_8')\n",
    "impute_df(df,'loc_og_t2c_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "\n",
    "impute_df(df,'loc_og_mou_6')\n",
    "impute_df(df,'loc_og_mou_7')\n",
    "impute_df(df,'loc_og_mou_8')\n",
    "impute_df(df,'loc_og_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_og_t2t_mou_6')\n",
    "impute_df(df,'std_og_t2t_mou_7')\n",
    "impute_df(df,'std_og_t2t_mou_8')\n",
    "impute_df(df,'std_og_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_og_t2t_mou_6')\n",
    "impute_df(df,'std_og_t2t_mou_7')\n",
    "impute_df(df,'std_og_t2t_mou_8')\n",
    "impute_df(df,'std_og_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_og_t2m_mou_6')\n",
    "impute_df(df,'std_og_t2m_mou_7')\n",
    "impute_df(df,'std_og_t2m_mou_8')\n",
    "impute_df(df,'std_og_t2m_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_og_t2f_mou_6')\n",
    "impute_df(df,'std_og_t2f_mou_7')\n",
    "impute_df(df,'std_og_t2f_mou_8')\n",
    "impute_df(df,'std_og_t2f_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_og_t2c_mou_6')\n",
    "impute_df(df,'std_og_t2c_mou_7')\n",
    "impute_df(df,'std_og_t2c_mou_8')\n",
    "impute_df(df,'std_og_t2c_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_og_mou_6')\n",
    "impute_df(df,'std_og_mou_7')\n",
    "impute_df(df,'std_og_mou_8')\n",
    "impute_df(df,'std_og_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'isd_og_mou_6')\n",
    "impute_df(df,'isd_og_mou_7')\n",
    "impute_df(df,'isd_og_mou_8')\n",
    "impute_df(df,'isd_og_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'spl_og_mou_6')\n",
    "impute_df(df,'spl_og_mou_7')\n",
    "impute_df(df,'spl_og_mou_8')\n",
    "impute_df(df,'spl_og_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'og_others_6')\n",
    "impute_df(df,'og_others_7')\n",
    "impute_df(df,'og_others_8')\n",
    "impute_df(df,'og_others_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_ic_t2t_mou_6')\n",
    "impute_df(df,'loc_ic_t2t_mou_7')\n",
    "impute_df(df,'loc_ic_t2t_mou_8')\n",
    "impute_df(df,'loc_ic_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_ic_t2m_mou_6')\n",
    "impute_df(df,'loc_ic_t2m_mou_7')\n",
    "impute_df(df,'loc_ic_t2m_mou_8')\n",
    "impute_df(df,'loc_ic_t2m_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_ic_t2f_mou_6')\n",
    "impute_df(df,'loc_ic_t2f_mou_7')\n",
    "impute_df(df,'loc_ic_t2f_mou_8')\n",
    "impute_df(df,'loc_ic_t2f_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'loc_ic_mou_6')\n",
    "impute_df(df,'loc_ic_mou_7')\n",
    "impute_df(df,'loc_ic_mou_8')\n",
    "impute_df(df,'loc_ic_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_ic_t2t_mou_6')\n",
    "impute_df(df,'std_ic_t2t_mou_7')\n",
    "impute_df(df,'std_ic_t2t_mou_8')\n",
    "impute_df(df,'std_ic_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_ic_t2m_mou_6')\n",
    "impute_df(df,'std_ic_t2m_mou_7')\n",
    "impute_df(df,'std_ic_t2m_mou_8')\n",
    "impute_df(df,'std_ic_t2m_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_ic_t2f_mou_6')\n",
    "impute_df(df,'std_ic_t2f_mou_7')\n",
    "impute_df(df,'std_ic_t2f_mou_8')\n",
    "impute_df(df,'std_ic_t2f_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_ic_t2t_mou_6')\n",
    "impute_df(df,'std_ic_t2t_mou_7')\n",
    "impute_df(df,'std_ic_t2t_mou_8')\n",
    "impute_df(df,'std_ic_t2t_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_ic_t2o_mou_6')\n",
    "impute_df(df,'std_ic_t2o_mou_7')\n",
    "impute_df(df,'std_ic_t2o_mou_8')\n",
    "impute_df(df,'std_ic_t2o_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'std_ic_mou_6')\n",
    "impute_df(df,'std_ic_mou_7')\n",
    "impute_df(df,'std_ic_mou_8')\n",
    "impute_df(df,'std_ic_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'spl_ic_mou_6')\n",
    "impute_df(df,'spl_ic_mou_7')\n",
    "impute_df(df,'spl_ic_mou_8')\n",
    "impute_df(df,'spl_ic_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'isd_ic_mou_6')\n",
    "impute_df(df,'isd_ic_mou_7')\n",
    "impute_df(df,'isd_ic_mou_8')\n",
    "impute_df(df,'isd_ic_mou_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling the nan values with median values\n",
    "impute_df(df,'ic_others_6')\n",
    "impute_df(df,'ic_others_7')\n",
    "impute_df(df,'ic_others_8')\n",
    "impute_df(df,'ic_others_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the last days of each month\n",
    "df['date_of_last_rech_6'].fillna('6/30/2014',inplace=True)\n",
    "df['date_of_last_rech_7'].fillna('7/31/2014',inplace=True)\n",
    "df['date_of_last_rech_8'].fillna('8/31/2014',inplace=True)\n",
    "df['date_of_last_rech_9'].fillna('9/30/2014',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dropping circle_id\n",
    "df.drop(columns=['circle_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##converting the column mobile_number to object\n",
    "df['mobile_number'] = df['mobile_number'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##finding the average recharge amount for the month 6 and 7\n",
    "df['avg_rech_amt_6_7'] = (df['total_rech_amt_6']+df['total_rech_amt_7'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### finding the average revenue generated per user for the month of 6 and 7\n",
    "\n",
    "df['avg_arpu_6_7'] = round((df['arpu_6']+df['arpu_7'])/2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = df['avg_rech_amt_6_7'].quantile(.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HVC'] = df['avg_rech_amt_6_7'].map(lambda x: 1 if x > cut_off else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.HVC.sum()#checkpoint reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc = df[df['HVC'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_df(df):\n",
    "    if(df['total_ic_mou_9'] == 0) and (df['total_og_mou_9'] == 0) and (df['vol_2g_mb_9'] == 0) and (df['vol_3g_mb_9'] == 0):\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "df_hvc['Churn'] = df_hvc.apply(flag_df,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference: the number of churn cases is 2539"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"red\"> Inference: This seems to be a very imbalanced data. So, we first need to get a balanced data for deriving a model. In the next few steps we shall balance the record </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the churn counts\n",
    "churn_count_0, churn_count_1 = df_hvc['Churn'].value_counts()\n",
    "churn_count_0, churn_count_1 \n",
    "\n",
    "# Separate class\n",
    "\n",
    "churn_class_0 = df_hvc[df_hvc['Churn'] == 0]\n",
    "churn_class_1 = df_hvc[df_hvc['Churn'] == 1] # print the shape of the class\n",
    "\n",
    "print('class 0:', churn_class_0.shape)\n",
    "print('class 1:', churn_class_1.shape)\n",
    "\n",
    "# take a random szmple of the size of the number of churn records\n",
    "churn_class_0_cut = churn_class_0.sample(churn_count_1)\n",
    "\n",
    "df_hvc_balanced = pd.concat([churn_class_0_cut, churn_class_1], axis=0)\n",
    "\n",
    "print(\"total class of 1 and0:\",df_hvc_balanced['Churn'].value_counts())# plot the count after under-sampeling\n",
    "\n",
    "df_hvc_balanced['Churn'].value_counts().plot(kind='bar', title='count (target)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#churn customers\n",
    "df_hvc_balanced[['total_ic_mou_9','total_og_mou_9','vol_2g_mb_9','vol_3g_mb_9','Churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###removing all the columns of the _9 month\n",
    "df_hvc_balanced = df_hvc_balanced[df_hvc_balanced.columns.drop(list(df_hvc_balanced.filter(regex='_9')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for object type columns as they cannot be used in model building, and keep only numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced.isnull().sum()\n",
    "\n",
    "obj_cols = df_hvc_balanced.select_dtypes('object').columns\n",
    "obj_cols\n",
    "\n",
    "df_hvc_balanced.drop(columns=obj_cols,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for NaN values and replace by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_hvc_balanced.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced['total_rech_data_8'] = df_hvc_balanced['total_rech_data_8'].fillna(0)\n",
    "df_hvc_balanced['max_rech_data_8'] = df_hvc_balanced['max_rech_data_8'].fillna(0)\n",
    "df_hvc_balanced['count_rech_2g_8'] = df_hvc_balanced['count_rech_2g_8'].fillna(0)\n",
    "df_hvc_balanced['count_rech_3g_8'] = df_hvc_balanced['count_rech_3g_8'].fillna(0)\n",
    "df_hvc_balanced['av_rech_amt_data_8'] = df_hvc_balanced['av_rech_amt_data_8'].fillna(0)\n",
    "df_hvc_balanced['arpu_3g_8'] = df_hvc_balanced['arpu_3g_8'].fillna(0)\n",
    "df_hvc_balanced['night_pck_user_8'] = df_hvc_balanced['night_pck_user_8'].fillna(0)\n",
    "df_hvc_balanced['arpu_2g_8'] = df_hvc_balanced['arpu_2g_8'].fillna(0)\n",
    "df_hvc_balanced['fb_user_8'] = df_hvc_balanced['fb_user_8'].fillna(0)\n",
    "df_hvc_balanced.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 3:  EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets start analysis of the data\n",
    "# let us check how many HV customers and also what is the relationship between churn and HVC\n",
    "df[\"HVC\"].value_counts().plot.barh()\n",
    "df[\"HVC\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\" > Inference : we need to concentrate on 30% of the customers who can be termed high value </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next let us look at what is the relationship between churn and HVC\n",
    "# let us check how many Churn customers and also what is the relationship between churn and HVC\n",
    "df_hvc_balanced[\"Churn\"].value_counts().plot.barh()\n",
    "df_hvc_balanced[\"Churn\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\" > Inference :  We have a balanced dataset for building a model. next lets check for outliers and other preliminary data which could give us some insights</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the continuous variables\n",
    "temp_columns = df_hvc_balanced[['avg_arpu_6_7','avg_rech_amt_6_7']]\n",
    "# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\n",
    "temp_columns.describe(percentiles=[.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Inference : Among the HVC itself there is a huge variation. there are chances of outliers - we will put a box plot to analyse this. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot( y=df_hvc_balanced[\"avg_arpu_6_7\"] );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot( y=df_hvc_balanced[\"avg_rech_amt_6_7\"] );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Inference :There seems to some outliers and we really need to remove those records so that they do not skew the analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced = df_hvc_balanced[df_hvc_balanced['avg_rech_amt_6_7']  <= 5000]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the continuous variables\n",
    "temp_columns = df_hvc_balanced[['avg_arpu_6_7','avg_rech_amt_6_7']]\n",
    "# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\n",
    "temp_columns.describe(percentiles=[.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot( y=df_hvc_balanced[\"avg_rech_amt_6_7\"] );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.histplot(data=df_hvc_balanced, x=\"avg_rech_amt_6_7\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\" > Inference : there are very less records beyond 2000, so we will remove them too, we will try with the value counts by binning them, then take the call of deleting, if the records are very less in number we shall remove them </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hvc_balanced[\"avg_rech_amt_6_7\"].value_counts(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced = df_hvc_balanced[df_hvc_balanced['avg_rech_amt_6_7']  <= 2000]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced[\"avg_rech_amt_6_7\"].value_counts(bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot( y=df_hvc_balanced[\"avg_rech_amt_6_7\"].value_counts(bins=200));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\" > Inference : now the data looks good. there will be people who recharge for near 2000, so let us have these records for further processing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(df_hvc_balanced.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Inference : Nothing is infereable from this - we need to reduce the number of variables. it is better we perfrom tis after we find the top 10-15 variables using the rfe model </font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the continuous variables\n",
    "out_check = df_hvc_balanced[['avg_rech_amt_6_7','avg_arpu_6_7']]\n",
    "# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\n",
    "out_check.describe(percentiles=[.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning - outlier, Imputation, null values removal - (rishab) \n",
    "# Data Preparation - derived variables(hvc, churn, arpu) - (rishab)\n",
    "# EDA (univariate,bivariate, multivariate) (arthi)\n",
    "# model - (Logistic(arthi) , decision trees(arthi), random forest (rishab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = df_hvc_balanced.drop(['Churn'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y = df_hvc_balanced['Churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hvc_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 15)             # running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assesing the stats model\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(X_train_sm.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Churn':y_train.values, 'Churn_Prob':y_train_pred})\n",
    "y_train_pred_final['mobile_number'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : checking the confusion matirx and the other scores of accuracy, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Inference : Thats a good level of accuracy. but we will still check th vif and see if some variables can be removed to get a better predictability </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Checking VIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Inference:  There are a few variables with high VIF. It's best to drop these variables as they aren't helping much with prediction and unnecessarily making the model complex. So let's start by dropping that. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = col.drop(['total_ic_mou_8','loc_ic_mou_8','total_og_mou_8','std_ic_mou_8','offnet_mou_8'], 1)\n",
    "cols=[]\n",
    "\n",
    "for i in range(0,vif.shape[0]):\n",
    "    if vif['VIF'][i] > 20:\n",
    "        cols.append(vif['Features'][i])\n",
    "        \n",
    "\n",
    "col = col.drop(cols, 1)\n",
    "\n",
    "col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = res.predict(X_train_sm).values.reshape(-1)\n",
    "\n",
    "y_train_pred[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_train_pred_final['Churn_Prob'] = y_train_pred\n",
    "# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "y_train_pred_final.head()\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there seems to be no more impacts and multicollinearity - so we can proceeed with this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "print(confusion)\n",
    "print(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color =\"blue\">there seems to be no more impacts and multicollinearity - so we can proceeed with this split.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics beyond simply accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\" Sensitivity (Recall): \" , TP / float(TP+FN))\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(\" False positive rate:\" , FP / float(TN+FP))\n",
    "# positive predictive value \n",
    "print (\" Precision \", TP / float(TP+FP))\n",
    "# Negative predictive value\n",
    "print (\" True negatives rate:\",TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Plotting ROC, Tradeoffs, and Threshold cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ROC \n",
    "An ROC curve demonstrates several things:\n",
    "\n",
    "- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n",
    "- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )\n",
    "\n",
    "draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Finding Optimal Cutoff Point\n",
    "Optimal cutoff probability is that prob where we get balanced sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> inference :  the best results can be seen at between .5 and .6 where the sensitivty and specificty is .83,.73 and .77 and .83 respectiviely. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Inference  : From the curve above, ~.55 is the optimum point to take it as a cutoff probability. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.55 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.final_predicted )\n",
    "confusion2\n",
    "\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives\n",
    "\n",
    "Recall = TP / float(TP+FN)\n",
    "Precision = TP / float(TP+FP)\n",
    "\n",
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\" Sensitivity (Recall): \" , Recall)\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(\" False positive rate:\" , FP / float(TN+FP))\n",
    "# positive predictive value \n",
    "print (\" Precision :\", Precision)\n",
    "# Negative predictive value\n",
    "print (\" True negatives rate:\",TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calclulate the F1 score\n",
    "F1 = 2 * (Precision * Recall)/(Precision + Recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Inference : Not a bad F-score ! looks like the model is working </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall to Precision Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision score: \", precision_score(y_train_pred_final.Churn, y_train_pred_final.predicted))\n",
    "print(\"Recall score :\", recall_score(y_train_pred_final.Churn, y_train_pred_final.predicted))\n",
    "y_train_pred_final.Churn, y_train_pred_final.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Inference :  the thresholds correlate to ~.55  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_temp = X_test[col]\n",
    "X_test_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test_temp)\n",
    "y_test_pred = res.predict(X_test_sm)\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "y_test_df['mobile_number'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Churn_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex(['mobile_number','Churn','Churn_Prob'], axis=1)\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.42 else 0)\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_pred_final.Churn, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final.Churn, y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\" Sensitivity (Recall): \" , TP / float(TP+FN))\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(\" False positive rate:\" , FP / float(TN+FP))\n",
    "# positive predictive value \n",
    "print (\" Precision \", TP / float(TP+FP))\n",
    "# Negative predictive value\n",
    "print (\" True negatives rate:\",TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Inference : the current model is has a good prediction stats of 88% Sensitivity and True negatives detection as 85%  and a precision of 72%  and the variables that make a difference are  </font>\n",
    "    \n",
    "\n",
    "total_rech_num_8\t\n",
    "total_rech_num_7\t\n",
    "total_ic_mou_8\t\n",
    "std_ic_mou_8\t\n",
    "isd_ic_mou_8\t\n",
    "roam_og_mou_8\t\n",
    "ic_others_8\t\n",
    "sep_vbc_3g\t\n",
    "    \n",
    "And with this model applied to the records and the prob threshold value of more than .55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages for visualization\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH']\n",
    "\n",
    "from IPython.display import Image  \n",
    "#from sklearn.externals.six import StringIO  \n",
    "from six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tree with max_depth=3\n",
    "dot_data = StringIO()  \n",
    "\n",
    "export_graphviz(dt, out_file=dot_data, filled=True, rounded=True,\n",
    "                feature_names=X.columns, \n",
    "                class_names=['Churn', \"No Churn\"])\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())\n",
    "#Image(graph.create_png(),width=800,height=900)\n",
    "#graph.write_pdf(\"dt_heartdisease.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INference:\n",
    "1. the main variables that helps us decide are:\n",
    "- total_ic_mou_8\n",
    "- last_day_rch_amt_8\n",
    "- total_og_mou_8\n",
    "- total_rech_amt_8\n",
    "- loc_og_mou_8\n",
    "- roam_og_mou_8\n",
    "- arpu_2g_8\n",
    "\n",
    "####  paths to take\n",
    "\n",
    "if we look at this tree, to find the cases for churn the path to be followed are:\n",
    "- total_ic_mou_8 > 39.45, roam_og_mou_8<=0.015, total_rech_amt_8 > 267\n",
    "\n",
    "and for non churns\n",
    "- total_ic_mou_8 <=39.45, arpu_8 <=289.605, total_ic_mou_8 <= 3.74\n",
    "\n",
    "### <font color = \"blue\"> these are based on the fact gini gains between the nodes </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us now check on the feature importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\n",
    "    \"Var name\":X_train.columns,\n",
    "    \"Imp\":dt.feature_importances_\n",
    "})\n",
    "\n",
    "imp_df.sort_values(by=\"Imp\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Inference: the top features for the model can be considered from this list </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let us move on to find the accuracy and the outcome of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_train, y_train_pred))\n",
    "confusion = confusion_matrix(y_train, y_train_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "Recall = TP / float(TP+FN)\n",
    "Precision = TP / float(TP+FP)\n",
    "\n",
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\" Sensitivity (Recall): \" , Recall)\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(\" False positive rate:\" , FP / float(TN+FP))\n",
    "# positive predictive value \n",
    "print (\" Precision :\", Precision)\n",
    "# Negative predictive value\n",
    "print (\" True negatives rate:\",TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Inference : This model has a good sensitivity and precision and able to predict true positives, te=rue negative very well. We shall check on thr test data perfromance too and then move on to checking if the tuning of hyper parameters give even better results. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_test_pred))\n",
    "confusion = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "confusion \n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "Recall = TP / float(TP+FN)\n",
    "Precision = TP / float(TP+FP)\n",
    "\n",
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\" Sensitivity (Recall): \" , Recall)\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(\" False positive rate:\" , FP / float(TN+FP))\n",
    "# positive predictive value \n",
    "print (\" Precision :\", Precision)\n",
    "# Negative predictive value\n",
    "print (\" True negatives rate:\",TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Inference : this model is good in predicting the churn vs no churns for the test data too very well</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Let us calculate the impurity measures </font>\n",
    "\n",
    "Let us find the classifcation of errors\n",
    "Churn = 0    no of cases - 18930\n",
    "Churn = 1    no of cases - 1745\n",
    "\n",
    "\n",
    "\n",
    "p(0) = 18930/20675 = .91\n",
    "p(1) = 1745/20675 = .08\n",
    "\n",
    "Since P(max) here is .91 : we can say that classification error could possibly become (1-.91) = .09. the chance of wrongly predicting a wrong no churn is .09.. this means incase we are saying all of them will not churn, we could possibly be wrong .09 % of times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us start playing with the hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_graph(dt_classifier):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(dt_classifier, out_file=dot_data, filled=True,rounded=True,\n",
    "                    feature_names=X.columns, \n",
    "                    class_names=['Churn', \"No Churn\"])\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dt_classifier):\n",
    "    print(\"Train Accuracy :\", accuracy_score(y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"Train Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Test Accuracy :\", accuracy_score(y_test, dt_classifier.predict(X_test)))\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, dt_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"violet\"> Case 1 : all default parameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_default = DecisionTreeClassifier(random_state=42)\n",
    "dt_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(dt_default)\n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Inference : this is a overfit. iwth train accuracy as 1. but test accuracy is good enough at .78. we will try the other parameters now</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"violet\"> Case 2 - max_depth = 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_depth = DecisionTreeClassifier(max_depth=3)\n",
    "dt_depth.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(dt_depth) \n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"violet\"> Case 3 - max_samples_split = 20 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_min_split = DecisionTreeClassifier(min_samples_split=20)\n",
    "dt_min_split.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(dt_min_split) \n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_min_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"violet\"> Case 4 - max_samples_leaf = 20 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_min_leaf = DecisionTreeClassifier(min_samples_leaf=20, random_state=42)\n",
    "dt_min_leaf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(dt_min_leaf)\n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_min_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Entropy instead of Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"violet\"> Case 5 - for the impurity checks, instead of gini let us play with the entropy values </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_min_leaf_entropy = DecisionTreeClassifier(min_samples_leaf=20, random_state=42, criterion=\"entropy\")\n",
    "dt_min_leaf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(dt_min_leaf_entropy)\n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_min_leaf_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"violet\"> Case 6 -- enough of trying one by one, let us try all the posible values for the hyperparamter vaiables and check on the results once for all using the gridsearch </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=dt, \n",
    "                           param_grid=params, \n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(grid_search.cv_results_)\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.nlargest(5,\"mean_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = grid_search.best_estimator_\n",
    "dt_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(dt_best)\n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Final inference: this tree with depth 5 and sample_leaf of 10 gives the best results. let us now again see which are the varibles that matter </font>\n",
    "\n",
    "the variables that now matter are \n",
    "- total_ic_mou_8\n",
    "- arpu_8\n",
    "- vol_2g_mb_8\n",
    "- Onnet_mou_8\n",
    "- aon\n",
    "- last_day_rch_amt_8\n",
    "- total_rech_amt_8\n",
    "- roam_og_mou_8\n",
    "\n",
    "for the non churns the best path to take:\n",
    "total_ic_mou_8 <=39.475 and arp_8<= 289.685 and total_ic_mou_8<=3.74 and vol_2g_mb_8 <= . 395 and onnet_mou_8 >.036\n",
    "\n",
    "for churns\n",
    "total_ic_mou_8 > 39.475 and roam_og_mou_8 <= .05 and total_rech_amt_8 > 267 and last_day_rch_amt_8 <=3.5 and aon > 417.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing libraries\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=10, max_depth=3,oob_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(rf,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tree = rf.estimators_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(sample_tree)\n",
    "Image(gph.create_png(), width=700, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(rf.estimators_[2])\n",
    "Image(gph.create_png(), width=700, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1,oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [1, 2, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'max_features': [2,3,4],\n",
    "    'n_estimators': [5,10,15,20,25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=classifier_rf, param_grid=params, \n",
    "                          cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = grid_search.best_estimator_\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(rf_best,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tree = rf_best.estimators_[0]\n",
    "sample_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(sample_tree)\n",
    "Image(gph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(rf_best.estimators_[0])\n",
    "Image(gph.create_png(), height=600, width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = get_dt_graph(rf_best.estimators_[10])\n",
    "Image(gph.create_png(), height=600, width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable importance in RandomForest and Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\n",
    "    \"Varname\": X_train.columns,\n",
    "    \"Imp\": rf_best.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df.sort_values(by=\"Imp\", ascending=False,inplace=True)\n",
    "imp_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference :  the following are the most important features that can help us predict the churn\n",
    "107\tmax_rech_amt_8\t0.058130\n",
    "32\tloc_og_mou_8\t0.054670\n",
    "110\tlast_day_rch_amt_8\t0.047455\n",
    "101\ttotal_rech_num_8\t0.043871\n",
    "14\troam_ic_mou_8\t0.040802\n",
    "71\tloc_ic_mou_8\t0.035608\n",
    "20\tloc_og_t2t_mou_8\t0.033673\n",
    "86\tstd_ic_mou_8\t0.033327\n",
    "65\tloc_ic_t2m_mou_8\t0.033213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"Green\"> Final word: With the 3 models we notice that the Random forests are much more reliable and has the best prediction as compared to the Decision tree or logistics regression. </font>\n",
    "    \n",
    "   ## Also, the balancing of the data was very important for getting the balanced results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
